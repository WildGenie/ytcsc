{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import numpy as np\n",
    "\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Dropout, Activation, Input, Bidirectional, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Flatten, TimeDistributed, GlobalMaxPooling1D, GlobalMaxPool1D\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from tensorflow import keras \n",
    "from tensorflow.python.keras import backend as k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/tensorflow/tensorflow/issues/33721\n",
    "TF_FORCE_GPU_ALLOW_GROWTH=1\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "import os\n",
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"]=\"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load IMDB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMDB dataset\n",
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = 5000\n",
    "(X_train_imdb, y_train_imdb), (X_test_imdb, y_test_imdb) = imdb.load_data(num_words=word_count)\n",
    "max_length = 500\n",
    "X_train_imdb = sequence.pad_sequences(X_train_imdb, maxlen=max_length)\n",
    "X_test_imdb = sequence.pad_sequences(X_test_imdb, maxlen=max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load my dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_no_trans_stem = pd.read_csv('../data/preproc_no_trans_stem.csv')\n",
    "#data_trans = pd.read_csv('../data/preproc_trans.csv')\n",
    "data_stem = pd.read_csv('../data/preproc_stem.csv')\n",
    "#data_trans_stem = pd.read_csv('../data/preproc_trans_stem.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, make sure the negative and positive comments are even in numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    3053\n",
       " 0    1950\n",
       " 1    1379\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_no_trans_stem.rating.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are more negatives, drop random negative sentiment comments.\n",
    "\n",
    "Remove neutral sentiment comments from the training data, but keep it for word vector training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_no_trans_stem = data_no_trans_stem.copy()\n",
    "w2v_stem = data_stem.copy()\n",
    "\n",
    "data_no_trans_stem = data_no_trans_stem.loc[data_no_trans_stem.rating != -1]\n",
    "data_stem = data_stem.loc[data_stem.rating != -1]\n",
    "\n",
    "negative_indices = data_no_trans_stem.index[data_no_trans_stem.rating == 0].tolist()\n",
    "diff = abs(np.diff(data_no_trans_stem.rating.value_counts().values)[0])\n",
    "indices = np.random.choice(negative_indices, diff, replace=False)\n",
    "data_no_trans_stem = data_no_trans_stem.drop(indices)\n",
    "#data_trans = data_trans.drop(indices)\n",
    "data_stem = data_stem.drop(indices)\n",
    "#data_trans_stem = data_trans_stem.drop(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_no_trans_stem = [[word for word in str(body).split()] for body in data_no_trans_stem.body]\n",
    "#sentences_trans = [[word for word in str(body).split()] for body in data_trans.body]\n",
    "sentences_stem = [[word for word in str(body).split()] for body in data_stem.body]\n",
    "#sentences_trans_stem = [[word for word in str(body).split()] for body in data_trans_stem.body]\n",
    "sentences_w2v_no_trans_stem = [[word for word in str(body).split()] for body in w2v_no_trans_stem.body]\n",
    "sentences_w2v_stem = [[word for word in str(body).split()] for body in w2v_stem.body]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "seed = 1234\n",
    "min_word_count = 1\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2vec model based on all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word2vec = KeyedVectors.load_word2vec_format(word_vectors_file, binary=True)\n",
    "word2vec = Word2Vec(sentences=sentences_w2v_no_trans_stem, seed=random_state, min_count=min_word_count)\n",
    "#word2vec =  Word2Vec.load('../models/word2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('how', 0.9998462200164795),\n",
       " ('have', 0.9998425245285034),\n",
       " ('but', 0.9998337030410767),\n",
       " ('why', 0.9998334646224976),\n",
       " ('get', 0.99983149766922),\n",
       " ('laugh', 0.9998247027397156),\n",
       " ('game', 0.9998226761817932),\n",
       " ('much', 0.999820351600647),\n",
       " ('now', 0.999815046787262),\n",
       " ('should', 0.9998099207878113)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.wv.most_similar('hate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_weights = word2vec.wv.vectors\n",
    "vocab_size, emdedding_size = word2vec.wv.vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizer based on all dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=vocab_size)\n",
    "tokenizer.fit_on_texts(sentences_no_trans_stem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure the sentences are padded so that they all are the same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tokenizer.texts_to_sequences(sentences_no_trans_stem)\n",
    "X = sequence.pad_sequences(X)\n",
    "Y = data_no_trans_stem.rating.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data  to 70% for training and 30% for testing. 10% of the training data goes into validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t, X_tt, Y_t, Y_tt = train_test_split(X, Y, test_size = 0.3, random_state = random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different NN architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_model(model, params):\n",
    "    model.add(LSTM(params['lstm_units'], return_sequences=True, go_backwards=True))\n",
    "    return model\n",
    "\n",
    "def bilstm_model(model, params):\n",
    "    model.add(Bidirectional(LSTM(params['lstm_units'], return_sequences=True)))\n",
    "    return model\n",
    "\n",
    "def cnn_model(model, params):\n",
    "    model.add(Conv1D(params['filters'], params['kernels'], padding='same'))\n",
    "    model.add(MaxPooling1D(pool_size=params['pools']))\n",
    "    return model\n",
    "\n",
    "def cnnlstm_model(model,params):\n",
    "    model.add(cnn_model(model, params))\n",
    "    model.add(lstm_model(model, params))\n",
    "    return model\n",
    "\n",
    "def cnnbilstm_model(model, params):\n",
    "    model.add(cnn_model(model, params))\n",
    "    model.add(bilstm_model(model, params))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model building functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(input_layer, add_layers, params):\n",
    "    model = Sequential()\n",
    "    model.add(input_layer)\n",
    "    model = add_hidden_layers(model, params, add_layers)\n",
    "    if params['timedist_output']:\n",
    "        model.add(TimeDistributed(Dense(1, activation='sigmoid')))\n",
    "    else:\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "def add_hidden_layers(model, params, add_layers):\n",
    "    if add_layers == 'lstm':\n",
    "        model = lstm_model(model, params)\n",
    "    elif add_layers == 'bilstm':\n",
    "        model = bilstm_model(model, params)\n",
    "    elif add_layers == 'cnn':\n",
    "        model = cnn_model(model, params)\n",
    "    elif add_layers == 'cnnlstm':\n",
    "        model = cnnlstm_model(model, params)\n",
    "    elif add_layers == 'cnnbilstm':\n",
    "        model = cnnbilstm_model(model, params)\n",
    "    return model\n",
    "\n",
    "def compile_model(model, params):\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer=str(params['optimizer']), metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "def fit_model(model, model_name, params, X_train, Y_train, X_val, Y_val):\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "    #path = '../models/checkpoints/'\n",
    "    #param_values = \"-\".join(str(v) for v in params.values() if type(v) != Embedding)\n",
    "    #print(param_values)\n",
    "    #file_name = path+param_values+'.h5'\n",
    "    #model_checkpoint = ModelCheckpoint(file_name, save_best_only=True, save_weights_only=True)\n",
    "    callbacks = [early_stopping]#, model_checkpoint]\n",
    "    hist = model.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs=30, batch_size=params['batch'], verbose = 2, callbacks=[callbacks])\n",
    "    return model, hist\n",
    "\n",
    "def cross_val(X, Y, model, params):\n",
    "    temp_acc = 0\n",
    "    best_model = None\n",
    "    best_hist = None\n",
    "    for train_index, val_index in sk.split(X,Y):\n",
    "        X_train, X_val = X[train_index], X[val_index]\n",
    "        y_train, y_val = Y[train_index], Y[val_index]\n",
    "        model, hist = fit_model(model, params['models'], params, X_train, y_train, X_val, y_val)\n",
    "        loss, acc = model.evaluate(X_tt, Y_tt, verbose = 2, batch_size = params['batch'])\n",
    "        if acc > temp_acc:\n",
    "            best_model = model\n",
    "            best_hist = hist\n",
    "            temp_acc = acc\n",
    "    return best_hist, temp_acc, best_model\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Grid search parameters\n",
    "optimizers = ['rmsprop', 'adam']\n",
    "batch_sizes = [64, 256]\n",
    "lstm_units = [32, 64, 128, 256]\n",
    "filters = lstm_units\n",
    "kernels = [2, 3]\n",
    "pools = [2, 3]\n",
    "timedist_output = [True, False]\n",
    "embed_layers = [\n",
    "    Embedding(input_dim=vocab_size, output_dim=emdedding_size, weights=[word2vec.wv.vectors]), # with w2v vector weights\n",
    "    Embedding(X.max()+1, 32, input_length=X.shape[1])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation setup\n",
    "sk = StratifiedKFold(n_splits = 3, random_state = random_state, shuffle = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For tracking best performing model\n",
    "current_acc = 0\n",
    "best_results = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For tracking the result of all the tests\n",
    "results = []\n",
    "params = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bilstm-adam-256-256-False\n",
      "Epoch 1/30\n",
      "6/6 [==============================] - 1s 144ms/step - loss: 0.0427 - accuracy: 0.9929 - val_loss: 0.0215 - val_accuracy: 0.9968\n",
      "Epoch 2/30\n",
      "6/6 [==============================] - 1s 137ms/step - loss: 0.0407 - accuracy: 0.9929 - val_loss: 0.0207 - val_accuracy: 0.9968\n",
      "Epoch 3/30\n",
      "6/6 [==============================] - 1s 134ms/step - loss: 0.0387 - accuracy: 0.9929 - val_loss: 0.0204 - val_accuracy: 0.9968\n",
      "Epoch 4/30\n",
      "6/6 [==============================] - 1s 134ms/step - loss: 0.0378 - accuracy: 0.9929 - val_loss: 0.0204 - val_accuracy: 0.9968\n",
      "Epoch 5/30\n",
      "6/6 [==============================] - 1s 136ms/step - loss: 0.0371 - accuracy: 0.9929 - val_loss: 0.0204 - val_accuracy: 0.9968\n",
      "Epoch 6/30\n",
      "6/6 [==============================] - 1s 136ms/step - loss: 0.0368 - accuracy: 0.9929 - val_loss: 0.0205 - val_accuracy: 0.9968\n",
      "Epoch 7/30\n",
      "6/6 [==============================] - 1s 136ms/step - loss: 0.0366 - accuracy: 0.9929 - val_loss: 0.0205 - val_accuracy: 0.9968\n",
      "Epoch 8/30\n",
      "6/6 [==============================] - 1s 133ms/step - loss: 0.0364 - accuracy: 0.9929 - val_loss: 0.0204 - val_accuracy: 0.9968\n",
      "Epoch 9/30\n",
      "6/6 [==============================] - 1s 134ms/step - loss: 0.0363 - accuracy: 0.9929 - val_loss: 0.0202 - val_accuracy: 0.9968\n",
      "Epoch 10/30\n",
      "6/6 [==============================] - 1s 133ms/step - loss: 0.0362 - accuracy: 0.9929 - val_loss: 0.0200 - val_accuracy: 0.9968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30\n",
      "6/6 [==============================] - 1s 137ms/step - loss: 0.0361 - accuracy: 0.9929 - val_loss: 0.0198 - val_accuracy: 0.9968\n",
      "Epoch 12/30\n",
      "6/6 [==============================] - 1s 137ms/step - loss: 0.0360 - accuracy: 0.9929 - val_loss: 0.0196 - val_accuracy: 0.9968\n",
      "Epoch 13/30\n",
      "6/6 [==============================] - 1s 134ms/step - loss: 0.0359 - accuracy: 0.9929 - val_loss: 0.0195 - val_accuracy: 0.9967\n",
      "Epoch 14/30\n",
      "6/6 [==============================] - 1s 137ms/step - loss: 0.0357 - accuracy: 0.9928 - val_loss: 0.0194 - val_accuracy: 0.9966\n",
      "Epoch 15/30\n",
      "6/6 [==============================] - 1s 136ms/step - loss: 0.0485 - accuracy: 0.9900 - val_loss: 0.2771 - val_accuracy: 0.9545\n",
      "Epoch 16/30\n",
      "6/6 [==============================] - 1s 136ms/step - loss: 0.3806 - accuracy: 0.8528 - val_loss: 0.2497 - val_accuracy: 0.9655\n",
      "Epoch 17/30\n",
      "6/6 [==============================] - 1s 136ms/step - loss: 0.1734 - accuracy: 0.9706 - val_loss: 0.0527 - val_accuracy: 0.9897\n",
      "Epoch 18/30\n",
      "6/6 [==============================] - 1s 136ms/step - loss: 0.0666 - accuracy: 0.9858 - val_loss: 0.0236 - val_accuracy: 0.9966\n",
      "Epoch 19/30\n",
      "6/6 [==============================] - 1s 133ms/step - loss: 0.0414 - accuracy: 0.9920 - val_loss: 0.0404 - val_accuracy: 0.9937\n",
      "Epoch 20/30\n",
      "6/6 [==============================] - 1s 137ms/step - loss: 0.0422 - accuracy: 0.9920 - val_loss: 0.0410 - val_accuracy: 0.9937\n",
      "Epoch 21/30\n",
      "6/6 [==============================] - 1s 136ms/step - loss: 0.0521 - accuracy: 0.9906 - val_loss: 0.1175 - val_accuracy: 0.9832\n",
      "Epoch 22/30\n",
      "6/6 [==============================] - 1s 133ms/step - loss: 0.2941 - accuracy: 0.9540 - val_loss: 0.2266 - val_accuracy: 0.9523\n",
      "Epoch 23/30\n",
      "6/6 [==============================] - 1s 134ms/step - loss: 0.2296 - accuracy: 0.9447 - val_loss: 0.1310 - val_accuracy: 0.9674\n",
      "Epoch 24/30\n",
      "6/6 [==============================] - 1s 135ms/step - loss: 0.1496 - accuracy: 0.9635 - val_loss: 0.0390 - val_accuracy: 0.9952\n"
     ]
    }
   ],
   "source": [
    "# Gridsearch with cross validation performed. The average result is saved\n",
    "models = ['lstm', 'bilstm']\n",
    "for m in models:\n",
    "    print('Running ', m, ' model')\n",
    "    params['models'] = m\n",
    "    for o in optimizers:\n",
    "        params['optimizer'] = o\n",
    "        for batch in batch_sizes:\n",
    "            params['batch'] = batch\n",
    "            for lu in lstm_units:\n",
    "                params['lstm_units'] = lu\n",
    "                for e in embed_layers:\n",
    "                    for t in timedist_output:\n",
    "                        params['timedist_output'] = t\n",
    "                        model = make_model(e, m, params)\n",
    "                        model = compile_model(model, params)\n",
    "                        best_hist, temp_acc, best_model = cross_val(X_t, Y_t, model, params)\n",
    "                        results.append([best_hist, temp_acc, best_model])\n",
    "                        if temp_acc > current_acc:\n",
    "                            current_acc = temp_acc\n",
    "                            params['e'] = e\n",
    "                            best_results = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[<tensorflow.python.keras.callbacks.History at 0x268150bd208>,\n",
       "  0.793963611125946,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x2680d750088>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x26850df4488>,\n",
       "  0.8084225058555603,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x268416c5788>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x268724f95c8>,\n",
       "  0.7979141473770142,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x26850e07808>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x2688494ce08>,\n",
       "  0.8012832999229431,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x26872509f08>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x2688c618308>,\n",
       "  0.8117917776107788,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x26880f877c8>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x2688c2c03c8>,\n",
       "  0.803422212600708,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x2688c4b7dc8>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x268a4381e48>,\n",
       "  0.8018251657485962,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x268a016ffc8>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x268a8ed1e88>,\n",
       "  0.8063343167304993,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x268a4367448>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x268a90fb888>,\n",
       "  0.7996240258216858,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x268a8eda4c8>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x268a9124c48>,\n",
       "  0.7999289035797119,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x268ac4c5848>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x268b2d45f08>,\n",
       "  0.8023668527603149,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x268a8e126c8>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x268b2f3ca88>,\n",
       "  0.7919036746025085,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x268b1bc9e88>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x268b6537d88>,\n",
       "  0.7931114435195923,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x268b67c45c8>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x268b6c41e08>,\n",
       "  0.7884498834609985,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x268a4317948>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x268c7d46f08>,\n",
       "  0.798850953578949,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x268b6c244c8>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x268cc7b4b48>,\n",
       "  0.7964185476303101,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x268c8ffbe88>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x268cb63b8c8>,\n",
       "  0.8020508885383606,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x268cc618508>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x268cc67ad08>,\n",
       "  0.8062496185302734,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x268cf25ab88>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x268cf371148>,\n",
       "  0.8011253476142883,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x268c9014388>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x268d8d33188>,\n",
       "  0.7861642241477966,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x268cf318f48>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x268da3c48c8>,\n",
       "  0.8049347400665283,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x268d8b8ae48>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x268da3c7148>,\n",
       "  0.807880699634552,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x268da26c8c8>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x268d8d2d148>,\n",
       "  0.7904532551765442,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x268ee4882c8>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x268dc6cad08>,\n",
       "  0.7928574681282043,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x268d8e865c8>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x268f6c851c8>,\n",
       "  0.8042744994163513,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x268dc7f4f08>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x268fa5b4f48>,\n",
       "  0.7941330075263977,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x268fa173648>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x269010ee608>,\n",
       "  0.7870727181434631,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x268fa590d48>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x2690127a908>,\n",
       "  0.7853909730911255,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x269013ab2c8>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x26905a5c4c8>,\n",
       "  0.805995762348175,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x26905b35608>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x268cc64ae48>,\n",
       "  0.7981398701667786,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x268f6c8f948>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x268c6c788c8>,\n",
       "  0.7812203764915466,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x268c6be84c8>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x269320793c8>,\n",
       "  0.7786920666694641,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x269011a6a48>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x269336091c8>,\n",
       "  0.7927445769309998,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x2692a811648>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x269370de208>,\n",
       "  0.7950471639633179,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x2693375ae88>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x2693dc38888>,\n",
       "  0.7762314081192017,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x26936f94948>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x2694120a248>,\n",
       "  0.780960738658905,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x2693dc4fe48>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x268c6bf3fc8>,\n",
       "  0.7938789129257202,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x2693efaed48>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x26905d2c188>,\n",
       "  0.7868921160697937,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x26901476348>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x26942620408>,\n",
       "  0.7830489873886108,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x2692a864dc8>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x26942aeb1c8>,\n",
       "  0.7772811055183411,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x2694275a0c8>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x2694baec708>,\n",
       "  0.7966217398643494,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x2694baf4608>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x2694d23c888>,\n",
       "  0.7812035083770752,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x2694d37c6c8>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x2695636e4c8>,\n",
       "  0.7764458656311035,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x2694f929808>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x2695adb6e88>,\n",
       "  0.7728847861289978,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x269560acfc8>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x2695ac5cd88>,\n",
       "  0.7764740586280823,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x26959aef188>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x269560a8c48>,\n",
       "  0.7837374210357666,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x2695c440208>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x26951df5dc8>,\n",
       "  0.7850579619407654,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x2694d262a08>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x2695aca3d88>,\n",
       "  0.7635389566421509,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x26905feb3c8>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x26967037cc8>,\n",
       "  0.7881788015365601,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x269060a6a88>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x269670cd988>,\n",
       "  0.8013566732406616,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x26967092488>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x269697ace48>,\n",
       "  0.7740924954414368,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x2696955cec8>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x26974f60c48>,\n",
       "  0.7624610662460327,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x26971839608>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x26975152988>,\n",
       "  0.8013623356819153,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x26974f4a688>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x26979d2bf88>,\n",
       "  0.79218590259552,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x269763c8c88>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x2697a077188>,\n",
       "  0.7785903811454773,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x26979fde988>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x26980bafe48>,\n",
       "  0.7716319561004639,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x26980b4a1c8>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x26984309148>,\n",
       "  0.7968700528144836,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x2698414d608>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x2697182bd08>,\n",
       "  0.7844823598861694,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x26979c0fa88>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x2694bb5ed48>,\n",
       "  0.7741490006446838,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x2694f977188>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x2695fcf97c8>,\n",
       "  0.7740135192871094,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x2695fd1b748>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x26979f4f888>,\n",
       "  0.7718350291252136,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x26979eda688>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x2692bce3948>,\n",
       "  0.78975909948349,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x2692bc5ec48>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x269993f44c8>,\n",
       "  0.7693744897842407,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x26986e08b48>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x2699cec7488>,\n",
       "  0.7729862928390503,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x2699957dfc8>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x2699ce6df48>,\n",
       "  0.7932412028312683,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x2699cd70a08>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x269a63e1348>,\n",
       "  0.798258364200592,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x2699f5fa408>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x269aaa9e908>,\n",
       "  0.7807350158691406,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x269aaaede48>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x26985990708>,\n",
       "  0.7849563956260681,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x269b1741548>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x2696ad1cf88>,\n",
       "  0.7931791543960571,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x26979efcc88>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x269717e0b48>,\n",
       "  0.8029086589813232,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x2696ac80b48>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x269b4dd6d88>,\n",
       "  0.791361927986145,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x269aac45608>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x269c5ba65c8>,\n",
       "  0.7900074124336243,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x269c58a0308>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x269cdfe48c8>,\n",
       "  0.7964524030685425,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x269cc821dc8>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x269d36aaf08>,\n",
       "  0.8041784763336182,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x269cc9f8f88>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x269e0166508>,\n",
       "  0.7939410209655762,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x269d84e5948>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x269e6f45308>,\n",
       "  0.7873266935348511,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x269d8493248>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x269dffa98c8>,\n",
       "  0.7968136668205261,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x269e6dd03c8>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x269aac33148>,\n",
       "  0.8237109184265137,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x269e7014808>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x269e83d3808>,\n",
       "  0.8009728789329529,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x269c5969748>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x269f9089948>,\n",
       "  0.7934669852256775,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x269e8423c08>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x269fb806988>,\n",
       "  0.8008149266242981,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x269f9096e48>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x269ffe00208>,\n",
       "  0.7985687851905823,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x269fdc99748>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x26a0d7d8fc8>,\n",
       "  0.7956059575080872,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x26a025fe488>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x26a0da32208>,\n",
       "  0.7954986095428467,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x26a0da9fc08>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x26a15ff49c8>,\n",
       "  0.8008826971054077,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x26a135ecc88>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x26a214e6308>,\n",
       "  0.7976940870285034,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x26a19703cc8>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x269fb767808>,\n",
       "  0.788066029548645,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x26a1cddf288>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x2696aca7248>,\n",
       "  0.7974287867546082,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x269f9096808>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x26a06cd1048>,\n",
       "  0.8005102276802063,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x26a21316d88>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x26a2f0e9e08>,\n",
       "  0.7891326546669006,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x26a149a3cc8>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x26a33725988>,\n",
       "  0.7912603616714478,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x26a3156a988>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x26a3a68c1c8>,\n",
       "  0.7950697541236877,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x26a3929a448>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x26a43a6f488>,\n",
       "  0.8068479895591736,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x26a4132fcc8>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x26a90e2f348>,\n",
       "  0.80561763048172,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x26a43a803c8>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x26a90e7e148>,\n",
       "  0.7908201217651367,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x26a8b756d48>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x26a97b81088>,\n",
       "  0.7896745204925537,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x26a97c15148>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x2698fd1c9c8>,\n",
       "  0.802276611328125,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x2698fa12308>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x26aa13dc4c8>,\n",
       "  0.7989582419395447,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x26aa144de48>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x26ab30f98c8>,\n",
       "  0.7902332544326782,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x26aac638188>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x26ab32c9a48>,\n",
       "  0.7974457144737244,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x26ab1ff1208>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x26a90cc88c8>,\n",
       "  0.7946802973747253,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x269ffe75b48>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x26aa1385048>,\n",
       "  0.793263852596283,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x26aa7f7b588>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x26aa81eb388>,\n",
       "  0.7884666919708252,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x26a225d67c8>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x26ab771f388>,\n",
       "  0.8070849776268005,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x26aa8265348>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x26ac99bdf48>,\n",
       "  0.8092803955078125,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x26ac73c15c8>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x26ad08a3d08>,\n",
       "  0.8077227473258972,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x26ac9b4efc8>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x26ada82d248>,\n",
       "  0.8038116097450256,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x26ad0769088>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x26ae1726448>,\n",
       "  0.7950415015220642,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x26adaac3e88>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x26ae42c58c8>,\n",
       "  0.8013114929199219,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x26ae15ce548>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x26aeb606f88>,\n",
       "  0.7935911417007446,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x26ae3fc4548>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x26af68f7fc8>,\n",
       "  0.7983937859535217,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x26aefcd88c8>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x26afd6f8208>,\n",
       "  0.7924850583076477,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x26af57eafc8>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x26afefdef88>,\n",
       "  0.8093593716621399,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x26afd6b7348>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x26aff2e2a88>,\n",
       "  0.808366060256958,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x26afefde288>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x26b05fa1148>,\n",
       "  0.7890310883522034,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x26b06021288>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x269bee2b5c8>,\n",
       "  0.7865252494812012,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x26aeb70c5c8>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x26af6901b08>,\n",
       "  0.8046526312828064,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x26a337a48c8>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x26adbbaf988>,\n",
       "  0.8064077496528625,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x26ae401e3c8>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x26b0ef2ad88>,\n",
       "  0.7778059244155884,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x26adbbc4e48>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x26b0edc4288>,\n",
       "  0.783240795135498,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x26aff202d48>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x26b261e6e08>,\n",
       "  0.7936532497406006,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x26b2380e748>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x26b2c117908>,\n",
       "  0.7893358469009399,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x26b277dc4c8>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x26b370858c8>,\n",
       "  0.7981962561607361,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x26b2be86248>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x26b3de17508>,\n",
       "  0.7824901342391968,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x26b37085e48>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x26b408243c8>,\n",
       "  0.7932355999946594,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x26b3de01248>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x26b40913cc8>,\n",
       "  0.7883538603782654,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x26b406bdfc8>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x26b5271fd08>,\n",
       "  0.7889464497566223,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x26b47606448>],\n",
       " [<tensorflow.python.keras.callbacks.History at 0x26b5829ad48>,\n",
       "  0.783285915851593,\n",
       "  <tensorflow.python.keras.engine.sequential.Sequential at 0x26b52736f08>]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YouTube dataset accuracy: 0.8237\n"
     ]
    }
   ],
   "source": [
    "results_np = np.array(results)\n",
    "accuracy_results = results_np[:, 1]\n",
    "indx = accuracy_results.argmax(axis=0)\n",
    "hist, acc, model = results[indx]\n",
    "print('YouTube dataset accuracy: %.4f' % acc)\n",
    "import json\n",
    "json.dump(hist.history, open('../models/history/bilstmadam256False.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_architecture = []\n",
    "models = ['lstm', 'bilstm']\n",
    "for m in models:\n",
    "    params['models'] = m\n",
    "    for o in optimizers:\n",
    "        params['optimizer'] = o\n",
    "        for batch in batch_sizes:\n",
    "            params['batch'] = batch\n",
    "            for lu in lstm_units:\n",
    "                params['lstm_units'] = lu\n",
    "                for e in embed_layers:\n",
    "                    for t in timedist_output:\n",
    "                        params['timedist_output'] = t\n",
    "                        params['e'] = e\n",
    "                        model_architecture.append(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'models': 'bilstm', 'optimizer': 'adam', 'batch': 256, 'lstm_units': 256, 'timedist_output': False, 'e': <tensorflow.python.keras.layers.embeddings.Embedding object at 0x000001C933A02C48>, 'kernels': 2, 'pools': 2, 'filters': 256}\n",
      "Epoch 1/10\n",
      "98/98 [==============================] - 30s 288ms/step - loss: 0.6934 - accuracy: 0.5255\n",
      "Epoch 2/10\n",
      "98/98 [==============================] - 28s 288ms/step - loss: 0.6810 - accuracy: 0.5668\n",
      "Epoch 3/10\n",
      "98/98 [==============================] - 28s 286ms/step - loss: 0.5876 - accuracy: 0.6861\n",
      "Epoch 4/10\n",
      "98/98 [==============================] - 28s 288ms/step - loss: 0.5094 - accuracy: 0.7715\n",
      "Epoch 5/10\n",
      "98/98 [==============================] - 29s 291ms/step - loss: 0.5279 - accuracy: 0.7481\n",
      "Epoch 6/10\n",
      "98/98 [==============================] - 29s 292ms/step - loss: 0.5057 - accuracy: 0.7463\n",
      "Epoch 7/10\n",
      "98/98 [==============================] - 28s 286ms/step - loss: 0.5087 - accuracy: 0.7189\n",
      "Epoch 8/10\n",
      "98/98 [==============================] - 28s 290ms/step - loss: 0.4699 - accuracy: 0.7671\n",
      "Epoch 9/10\n",
      "98/98 [==============================] - 28s 289ms/step - loss: 0.4499 - accuracy: 0.7831\n",
      "Epoch 10/10\n",
      "98/98 [==============================] - 28s 286ms/step - loss: 0.5045 - accuracy: 0.7243\n",
      "Accuracy: 74.60%\n"
     ]
    }
   ],
   "source": [
    "best_model_architecture = model_architecture[indx]\n",
    "# Since the shape of data is different, redo embedding layer\n",
    "best_model_architecture['e'] = Embedding(word_count, 32, input_length=max_length)\n",
    "print(best_model_architecture)\n",
    "# Test best performing architecture on IMDB data\n",
    "model = Sequential()\n",
    "model.add(best_model_architecture['e'])\n",
    "model.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "model.fit(X_train_imdb, y_train_imdb, epochs=10, batch_size=256)\n",
    "imdb_loss, imdb_acc = model.evaluate(X_test_imdb, y_test_imdb, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (imdb_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "results2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gridsearch with cross validation performed. The average result is saved\n",
    "models = ['cnn', 'cnnlstm', 'cnnbilstm']\n",
    "for m in models:\n",
    "    print('Running ', m, ' model')\n",
    "    params['models'] = m\n",
    "    for o in optimizers:\n",
    "        params['optimizer'] = o\n",
    "        for f in filters:\n",
    "            params['filters'] = f\n",
    "            for batch in batch_sizes:\n",
    "                params['batch'] = batch\n",
    "                if m == 'cnn':\n",
    "                    for k in kernels:\n",
    "                        params['kernels'] = k\n",
    "                        for p in pools:\n",
    "                            params['pools'] = p\n",
    "                            for e in embed_layers:\n",
    "                                for t in timedist_output:\n",
    "                                    params['timedist_output'] = t\n",
    "                                    model = make_model(e, m, params)\n",
    "                                    model = compile_model(model, params)\n",
    "                                    best_hist, temp_acc, best_model = cross_val(X_t, Y_t, model, params)\n",
    "                                    results2.append([best_hist, temp_acc, best_model])\n",
    "                                    if temp_acc > current_acc:\n",
    "                                        current_acc = temp_acc\n",
    "                                        params['e'] = e\n",
    "                                        best_results = params\n",
    "                else: #cnn lstm and cnn bilstm. saves iterations\n",
    "                    for k in kernels:\n",
    "                        params['kernels'] = k\n",
    "                        for p in pools:\n",
    "                            params['pools'] = p\n",
    "                            for lu in lstm_units:\n",
    "                                params['lstm_units'] = lu\n",
    "                                for e in embed_layers:\n",
    "                                    for t in timedist_output:\n",
    "                                        params['timedist_output'] = t\n",
    "                                        model = make_model(e, m, params)\n",
    "                                        model = compile_model(model, params)\n",
    "                                        best_hist, temp_acc, best_model = cross_val(X_t, Y_t, model, params)\n",
    "                                        results2.append([best_hist, temp_acc, best_model])\n",
    "                                        if temp_acc > current_acc:\n",
    "                                            current_acc = temp_acc\n",
    "                                            params['e'] = e\n",
    "                                            best_results = params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
