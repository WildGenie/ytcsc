{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import numpy as np\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, Dropout, Activation, Input\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_no_trans_stem = pd.read_csv('../data/preproc_no_trans_stem.csv')\n",
    "data_trans = pd.read_csv('../data/preproc_trans.csv')\n",
    "data_stem = pd.read_csv('../data/preproc_stem.csv')\n",
    "data_trans_stem = pd.read_csv('../data/preproc_trans_stem.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, make sure the negative and positive comments are even in numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    778\n",
       "1    555\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_no_trans_stem.rating.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are more negatives, drop random negative sentiment comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_indices = data_no_trans_stem.index[data_no_trans_stem.rating == 0].tolist()\n",
    "diff = abs(np.diff(data_no_trans_stem.rating.value_counts().values)[0])\n",
    "indices = np.random.choice(negative_indices, diff, replace=False)\n",
    "data_no_trans_stem = data_no_trans_stem.drop(indices)\n",
    "data_trans = data_trans.drop(indices)\n",
    "data_stem = data_stem.drop(indices)\n",
    "data_trans_stem = data_trans_stem.drop(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_no_trans_stem = [[word for word in str(body).split()] for body in data_no_trans_stem.body]\n",
    "sentences_trans = [[word for word in str(body).split()] for body in data_trans.body]\n",
    "sentences_stem = [[word for word in str(body).split()] for body in data_stem.body]\n",
    "sentences_trans_stem = [[word for word in str(body).split()] for body in data_trans_stem.body]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "seed = 1234\n",
    "min_word_count = 1\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2vec model based on all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = Word2Vec(\n",
    "sentences=sentences_no_trans_stem+sentences_trans+sentences_stem+sentences_trans_stem,\n",
    "seed=seed,\n",
    "min_count=min_word_count,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_weights = word2vec.wv.vectors\n",
    "vocab_size, emdedding_size = word2vec.wv.vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizer based on all dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(sentences_trans_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.zeros((vocab_size, emdedding_size))\n",
    "for word, i in words.items():\n",
    "    if word in word2vec.wv.vocab:\n",
    "        embeddings[i-1] = word2vec.wv[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=emdedding_size, weights=[word2vec.wv.vectors]))\n",
    "model.add(LSTM(units=emdedding_size))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer=Adam(learning_rate = 1e-4), metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tokenizer.texts_to_sequences(sentences_trans_stem)\n",
    "X = pad_sequences(X)\n",
    "Y = data_trans_stem.rating.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3, random_state = random_state)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state = random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6/6 - 1s - loss: 0.0189 - accuracy: 0.9957 - val_loss: 0.8634 - val_accuracy: 0.7179\n",
      "Epoch 2/100\n",
      "6/6 - 0s - loss: 0.0198 - accuracy: 0.9943 - val_loss: 0.7580 - val_accuracy: 0.7436\n",
      "Epoch 3/100\n",
      "6/6 - 0s - loss: 0.0197 - accuracy: 0.9957 - val_loss: 0.7710 - val_accuracy: 0.7564\n",
      "Epoch 4/100\n",
      "6/6 - 0s - loss: 0.0242 - accuracy: 0.9943 - val_loss: 0.8503 - val_accuracy: 0.7308\n",
      "Epoch 5/100\n",
      "6/6 - 0s - loss: 0.0184 - accuracy: 0.9971 - val_loss: 0.8960 - val_accuracy: 0.7308\n",
      "Epoch 6/100\n",
      "6/6 - 1s - loss: 0.0228 - accuracy: 0.9943 - val_loss: 1.0370 - val_accuracy: 0.7179\n",
      "Epoch 7/100\n",
      "6/6 - 1s - loss: 0.0203 - accuracy: 0.9957 - val_loss: 1.1513 - val_accuracy: 0.7179\n",
      "Epoch 8/100\n",
      "6/6 - 1s - loss: 0.0236 - accuracy: 0.9914 - val_loss: 1.2327 - val_accuracy: 0.7051\n",
      "Epoch 9/100\n",
      "6/6 - 1s - loss: 0.0199 - accuracy: 0.9943 - val_loss: 1.2310 - val_accuracy: 0.7308\n",
      "Epoch 10/100\n",
      "6/6 - 1s - loss: 0.0272 - accuracy: 0.9914 - val_loss: 1.1312 - val_accuracy: 0.6923\n",
      "Epoch 11/100\n",
      "6/6 - 1s - loss: 0.0187 - accuracy: 0.9943 - val_loss: 0.7734 - val_accuracy: 0.7564\n",
      "Epoch 12/100\n",
      "6/6 - 0s - loss: 0.0188 - accuracy: 0.9914 - val_loss: 0.7144 - val_accuracy: 0.7436\n",
      "Epoch 13/100\n",
      "6/6 - 1s - loss: 0.0188 - accuracy: 0.9943 - val_loss: 0.7840 - val_accuracy: 0.7179\n",
      "Epoch 14/100\n",
      "6/6 - 1s - loss: 0.0206 - accuracy: 0.9957 - val_loss: 0.7680 - val_accuracy: 0.7436\n",
      "Epoch 15/100\n",
      "6/6 - 1s - loss: 0.0177 - accuracy: 0.9943 - val_loss: 0.7213 - val_accuracy: 0.7564\n",
      "Epoch 16/100\n",
      "6/6 - 1s - loss: 0.0197 - accuracy: 0.9957 - val_loss: 0.8158 - val_accuracy: 0.7308\n",
      "Epoch 17/100\n",
      "6/6 - 1s - loss: 0.0160 - accuracy: 0.9971 - val_loss: 0.8788 - val_accuracy: 0.7308\n",
      "Epoch 18/100\n",
      "6/6 - 0s - loss: 0.0165 - accuracy: 0.9957 - val_loss: 0.8127 - val_accuracy: 0.7308\n",
      "Epoch 19/100\n",
      "6/6 - 1s - loss: 0.0181 - accuracy: 0.9928 - val_loss: 0.7775 - val_accuracy: 0.7564\n",
      "Epoch 20/100\n",
      "6/6 - 1s - loss: 0.0187 - accuracy: 0.9928 - val_loss: 0.8918 - val_accuracy: 0.7308\n",
      "Epoch 21/100\n",
      "6/6 - 1s - loss: 0.0159 - accuracy: 0.9957 - val_loss: 1.0406 - val_accuracy: 0.7051\n",
      "Epoch 22/100\n",
      "6/6 - 1s - loss: 0.0163 - accuracy: 0.9943 - val_loss: 1.0612 - val_accuracy: 0.7051\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2b444a94b48>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, validation_data=(X_val, Y_val), \n",
    "                 epochs=100, batch_size=128, verbose = 2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 - 0s - loss: 1.1345 - accuracy: 0.7057\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1344636678695679, 0.7057057023048401]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_test, verbose = 2, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
