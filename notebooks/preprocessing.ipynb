{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "import enchant\n",
    "from enchant.checker import SpellChecker\n",
    "import enchant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version\n",
      "3.7.8 (tags/v3.7.8:4b47a5b6ba, Jun 28 2020, 08:53:46) [MSC v.1916 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Python version\")\n",
    "print (sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../datasets/raw data/raw_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making the text more uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['preproc'] = df.body.replace(r'http\\S+', '', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change acronyms to words for uniformity. \n",
    "* https://www.netlingo.com/acronyms.php\n",
    "* https://blog.adioma.com/internet-acronyms-intro-list-infographic/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from util.acronyms_smileys import acronyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.preproc = df.preproc.str.lower()\n",
    "# the ’ was causing issues, took a while to notice\n",
    "df.preproc = df.preproc.str.replace('’', '\\'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.preproc = df.preproc.apply(lambda x: ' '.join(acronyms.get(word, word) for word in x.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of emojis defined from https://en.wikipedia.org/wiki/List_of_emoticons , https://emojipedia.org/people/\n",
    "\n",
    "Other references:\n",
    "* https://www.urbandictionary.com/define.php?term=%F0%9F%92%80\n",
    "* https://www.urbandictionary.com/define.php?term=%F0%9F%94%A5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "# list of tagged emoticons from above links\n",
    "from acronyms_smileys import smileys\n",
    "from acronyms_smileys import sent_acronyms\n",
    "# for removing untagged emoji\n",
    "import demoji\n",
    "#demoji.download_codes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_repeating_emoji(text):\n",
    "    uniques = set()\n",
    "    final_string = list()\n",
    "    text_arr = [item for item in emoji.get_emoji_regexp().split(text) if not item == '']\n",
    "    for e in text_arr:\n",
    "        # for some reason even though it is defined as '❤', when its \n",
    "        # imported, it gets loaded as '❤❤'\n",
    "        if e == '❤':\n",
    "            e = '❤❤'\n",
    "        if not bool(emoji.get_emoji_regexp().search(e)):\n",
    "            final_string.append(smileys.get(e, e))\n",
    "        else:\n",
    "            if e not in uniques:\n",
    "                uniques.add(e)\n",
    "                final_string.append(smileys.get(e, e))\n",
    "    return ' '.join(final_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find repeating emoticons and remove repetitions, and tag emoticons\n",
    "df.preproc = df.preproc.apply(lambda x: replace_repeating_emoji(x) if (bool(emoji.get_emoji_regexp().search(x)) and bool(re.search(r'(.)\\1', x))) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove untagged emoticons\n",
    "df.preproc = df.preproc.apply(lambda x : demoji.replace(x, ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set sentiment on acronyms (such as 'lol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.preproc = df.preproc.apply(lambda x: ' '.join(sent_acronyms.get(word, word) for word in x.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.preproc = df.preproc.apply(lambda x: ' '.join([word for word in x.split() if '#' not in word]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>rated</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>video_id</th>\n",
       "      <th>date</th>\n",
       "      <th>preproc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [body, positive, negative, neutral, rated, comment_id, video_id, date, preproc]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.preproc.str.contains('#')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace negations with \"not\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "negations = ['don\\'t', 'aint' 'aren\\'t', 'couldn\\'t','didn\\'t', \n",
    "             'doesn\\'t', 'hadn\\'t', 'hasn\\'t', 'haven\\'t', 'isn\\'t', \n",
    "             'mightn\\'t', 'mustn\\'t', 'needn\\'t', 'shouldn\\'t', 'wasn\\'t', \n",
    "             'weren\\'t', 'won\\'t', 'wouldn\\'t', 'nor', 'not', 'cant', 'dont',\n",
    "            'arent', 'couldnt', 'didnt', 'doesnt', 'hadnt', 'hasnt', 'havent',\n",
    "            'isnt', 'mightnt', 'mustnt', 'neednt', 'shouldnt', 'wasnt',\n",
    "            'werent', 'wont', 'wouldnt']\n",
    "regx = r'\\b(?:{})\\b'.format('|'.join(negations))\n",
    "df.preproc = df.preproc.str.replace(regx, 'not')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove negations from stop list, add two missing contractions\n",
    "stopwords_list = stopwords.words('english')\n",
    "stopwords_list = [el for el in stopwords_list if el not in negations]\n",
    "missing_words = ['i\\'m', 'i\\'d']\n",
    "stopwords_list.extend(missing_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 most commonly used words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "the     4158\n",
       "i       3446\n",
       "this    3072\n",
       "you     2635\n",
       "is      2582\n",
       "a       2337\n",
       "to      2195\n",
       "and     1819\n",
       "not     1598\n",
       "of      1454\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(' '.join(df.preproc).lower().split()).value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_common_stopwords(stop_words, n=5):\n",
    "    most_freq_words = pd.Series(' '.join(df.preproc).lower().split()).value_counts()[:int(n*2)].keys().to_numpy()\n",
    "    common_stopwords = [i for i in most_freq_words if i in stop_words]\n",
    "    return common_stopwords[0:n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove most common stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_stopwords = get_common_stopwords(stopwords_list, n=35)\n",
    "df.preproc = df.preproc.apply(lambda x: ' '.join([word for word in x.split() if word not in (common_stopwords)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove articles (the, an/a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = ['the', 'an', 'a']\n",
    "df.preproc = df.preproc.apply(lambda x: ' '.join([word for word in x.split() if word not in (articles)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>rated</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>video_id</th>\n",
       "      <th>date</th>\n",
       "      <th>preproc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>*stretched past the 10 minute mark for ad reve...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>UgztP4lVR-Epv5HlSXN4AaABAg</td>\n",
       "      <td>ItYOdWRo0JY</td>\n",
       "      <td>2020-01-10T20:24:33Z</td>\n",
       "      <td>*stretched past 10 minute mark ad revenue, see!*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>That makes no sense you sold a new phone for n...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Ugw3sxLwikkGsUza7hh4AaABAg</td>\n",
       "      <td>ItYOdWRo0JY</td>\n",
       "      <td>2020-03-22T19:13:19Z</td>\n",
       "      <td>makes sense sold new phone nothing ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WHY IS HE SO HAPPY HE JUST LOST $900 DOLLARS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Ugxe5-sz9eHyFCvZX4l4AaABAg</td>\n",
       "      <td>ItYOdWRo0JY</td>\n",
       "      <td>2020-10-30T12:27:57Z</td>\n",
       "      <td>happy lost $900 dollars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Does it work on iPads</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>UgxInsxWP8cnbFEh1Cp4AaABAg</td>\n",
       "      <td>ItYOdWRo0JY</td>\n",
       "      <td>2020-07-21T16:38:40Z</td>\n",
       "      <td>does work ipads</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yo ass better not have donated.. that cord mig...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Ugwn6_K1_792ARqfY4h4AaABAg</td>\n",
       "      <td>ItYOdWRo0JY</td>\n",
       "      <td>2019-12-23T13:35:04Z</td>\n",
       "      <td>yo ass better not donated.. cord might been ba...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body  positive  negative  \\\n",
       "0  *stretched past the 10 minute mark for ad reve...         0         1   \n",
       "1  That makes no sense you sold a new phone for n...         0         1   \n",
       "2       WHY IS HE SO HAPPY HE JUST LOST $900 DOLLARS         0         0   \n",
       "3                              Does it work on iPads         0         0   \n",
       "4  Yo ass better not have donated.. that cord mig...         0         0   \n",
       "\n",
       "   neutral  rated                  comment_id     video_id  \\\n",
       "0        0      1  UgztP4lVR-Epv5HlSXN4AaABAg  ItYOdWRo0JY   \n",
       "1        0      1  Ugw3sxLwikkGsUza7hh4AaABAg  ItYOdWRo0JY   \n",
       "2        1      1  Ugxe5-sz9eHyFCvZX4l4AaABAg  ItYOdWRo0JY   \n",
       "3        1      1  UgxInsxWP8cnbFEh1Cp4AaABAg  ItYOdWRo0JY   \n",
       "4        1      1  Ugwn6_K1_792ARqfY4h4AaABAg  ItYOdWRo0JY   \n",
       "\n",
       "                   date                                            preproc  \n",
       "0  2020-01-10T20:24:33Z   *stretched past 10 minute mark ad revenue, see!*  \n",
       "1  2020-03-22T19:13:19Z               makes sense sold new phone nothing ?  \n",
       "2  2020-10-30T12:27:57Z                            happy lost $900 dollars  \n",
       "3  2020-07-21T16:38:40Z                                    does work ipads  \n",
       "4  2019-12-23T13:35:04Z  yo ass better not donated.. cord might been ba...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "df.preproc = df.preproc.str.replace('[{}]'.format(string.punctuation), '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>rated</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>video_id</th>\n",
       "      <th>date</th>\n",
       "      <th>preproc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>*stretched past the 10 minute mark for ad reve...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>UgztP4lVR-Epv5HlSXN4AaABAg</td>\n",
       "      <td>ItYOdWRo0JY</td>\n",
       "      <td>2020-01-10T20:24:33Z</td>\n",
       "      <td>stretched past 10 minute mark ad revenue see</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>That makes no sense you sold a new phone for n...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Ugw3sxLwikkGsUza7hh4AaABAg</td>\n",
       "      <td>ItYOdWRo0JY</td>\n",
       "      <td>2020-03-22T19:13:19Z</td>\n",
       "      <td>makes sense sold new phone nothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WHY IS HE SO HAPPY HE JUST LOST $900 DOLLARS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Ugxe5-sz9eHyFCvZX4l4AaABAg</td>\n",
       "      <td>ItYOdWRo0JY</td>\n",
       "      <td>2020-10-30T12:27:57Z</td>\n",
       "      <td>happy lost 900 dollars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Does it work on iPads</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>UgxInsxWP8cnbFEh1Cp4AaABAg</td>\n",
       "      <td>ItYOdWRo0JY</td>\n",
       "      <td>2020-07-21T16:38:40Z</td>\n",
       "      <td>does work ipads</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yo ass better not have donated.. that cord mig...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Ugwn6_K1_792ARqfY4h4AaABAg</td>\n",
       "      <td>ItYOdWRo0JY</td>\n",
       "      <td>2019-12-23T13:35:04Z</td>\n",
       "      <td>yo ass better not donated cord might been bad ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body  positive  negative  \\\n",
       "0  *stretched past the 10 minute mark for ad reve...         0         1   \n",
       "1  That makes no sense you sold a new phone for n...         0         1   \n",
       "2       WHY IS HE SO HAPPY HE JUST LOST $900 DOLLARS         0         0   \n",
       "3                              Does it work on iPads         0         0   \n",
       "4  Yo ass better not have donated.. that cord mig...         0         0   \n",
       "\n",
       "   neutral  rated                  comment_id     video_id  \\\n",
       "0        0      1  UgztP4lVR-Epv5HlSXN4AaABAg  ItYOdWRo0JY   \n",
       "1        0      1  Ugw3sxLwikkGsUza7hh4AaABAg  ItYOdWRo0JY   \n",
       "2        1      1  Ugxe5-sz9eHyFCvZX4l4AaABAg  ItYOdWRo0JY   \n",
       "3        1      1  UgxInsxWP8cnbFEh1Cp4AaABAg  ItYOdWRo0JY   \n",
       "4        1      1  Ugwn6_K1_792ARqfY4h4AaABAg  ItYOdWRo0JY   \n",
       "\n",
       "                   date                                            preproc  \n",
       "0  2020-01-10T20:24:33Z       stretched past 10 minute mark ad revenue see  \n",
       "1  2020-03-22T19:13:19Z                makes sense sold new phone nothing   \n",
       "2  2020-10-30T12:27:57Z                             happy lost 900 dollars  \n",
       "3  2020-07-21T16:38:40Z                                    does work ipads  \n",
       "4  2019-12-23T13:35:04Z  yo ass better not donated cord might been bad ...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove repeating vowels and consonants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/46701245/how-to-replace-multiple-consecutive-repeating-characters-into-1-character-in-pyt\n",
    "df.preproc = df.preproc.apply(lambda x: ' '.join([re.sub(r'[^\\w\\s]|(.)(?=\\1)', '', word) for word in x.split()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tag any sequence of \"ha\" or \"ah\" (for example, \"ahaha\" or \"haha\") as a \"laugh\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.preproc = df.preproc.apply(lambda x: ' '.join([re.sub(r'([ha]+[ah]+).*\\1', r'laugh', word) for word in x.split()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.preproc = df.preproc.str.replace('\\d+', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_rating(row):\n",
    "    if row['positive'] == 1:\n",
    "        return 1\n",
    "    elif row['negative'] == 1:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 - negative, 1 - positive, -1 neutral\n",
    "df['rating'] = df.apply(lambda row: assign_rating(row), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write preprocessed column and the rating to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy relevant columns for later to file write\n",
    "data_no_trans_stem = df.filter(['comment_id', 'preproc', 'rating'], axis=1)\n",
    "data_no_trans_stem.columns = ['comment_id', 'body', 'rating']\n",
    "#data_trans = df.filter(['comment_id', 'preproc', 'rating'], axis=1)\n",
    "#data_trans.columns = ['comment_id', 'body', 'rating']\n",
    "data_stem = df.filter(['comment_id', 'preproc', 'rating'], axis=1)\n",
    "data_stem.columns = ['comment_id', 'body', 'rating']\n",
    "#data_trans_stem = df.filter(['comment_id', 'preproc', 'rating'], axis=1)\n",
    "#data_trans_stem.columns = ['comment_id', 'body', 'rating']\n",
    "data_long_cmnts = df.filter(['comment_id', 'preproc', 'rating'], axis=1)\n",
    "data_long_cmnts.columns = ['comment_id', 'body', 'rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix as many spelling errors as possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spell_checker = SpellChecker(\"en_UK\",\"en_US\")\n",
    "#def correct_error(body):\n",
    "#    spell_checker.set_text(body)\n",
    "#    for err in spell_checker:\n",
    "#        if len(err.suggest())>0: \n",
    "#            sug = err.suggest()[0]\n",
    "#            err.replace(sug)\n",
    "#    return spell_checker.get_text()\n",
    "#data_trans.body = data_trans.body.apply(lambda row: correct_error(row))\n",
    "#data_trans_stem.body = data_trans_stem.body.apply(lambda row: correct_error(row))\n",
    "#data_trans.body = data_trans.body.str.lower()\n",
    "#data_trans_stem.body = data_trans_stem.body.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stem the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "snows = nltk.stem.SnowballStemmer('english')\n",
    "data_stem.body = data_stem.body.apply(lambda x: ' '.join([snows.stem(word) for word in x.split()]))\n",
    "#data_trans_stem.body = data_trans_stem.body.apply(lambda x: ' '.join([snows.stem(word) for word in x.split()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate data with comments that have more than 5 words after all the preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'whi'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snows.stem('why')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6440, 3)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data_long_cmnts = data_long_cmnts[data_long_cmnts.body.str.split().str.len() >= 5]\n",
    "#data_long_cmnts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_no_trans_stem.to_csv('../datasets/preprocessed data/unstemmed/preproc_no_trans_stem.csv', index=False)\n",
    "#data_trans.to_csv('../data/preproc_trans.csv', index=False)\n",
    "data_stem.to_csv('../datasets/preprocessed data/stemmed/preproc_stem.csv', index=False)\n",
    "#data_trans_stem.to_csv('../data/preproc_trans_stem.csv', index=False)\n",
    "#data_long_cmnts.to_csv('../data/preproc_long.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
